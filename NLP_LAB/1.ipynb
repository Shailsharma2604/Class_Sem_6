{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'object': ['book'],\n",
       " 'verb': ['placed', 'smiled', 'walked', 'watched', 'flying'],\n",
       " 'adverb': ['carefully', 'Then', 'slowly']}"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import spacy\n",
    "\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "def find_object_verb_adverb(text):\n",
    "  doc = nlp(text)\n",
    "  results = {\"object\": [], \"verb\": [], \"adverb\": []}\n",
    "  for token in doc:\n",
    "    if token.dep_ == \"dobj\" and token.pos_ == \"NOUN\":\n",
    "      results[\"object\"].append(token.text)\n",
    "    elif token.pos_ == \"VERB\":\n",
    "        results[\"verb\"].append(token.text)\n",
    "    elif token.pos_ == \"ADV\":\n",
    "        results[\"adverb\"].append(token.text)\n",
    "  return results\n",
    "find_object_verb_adverb(\"She carefully placed the book on the shelf and smiled with satisfaction. Then, she walked slowly to the window and watched the birds flying in the sky.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\shail\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping corpora\\stopwords.zip.\n",
      "[nltk_data] Downloading package punkt_tab to\n",
      "[nltk_data]     C:\\Users\\shail\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping tokenizers\\punkt_tab.zip.\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt_tab')\n",
    "stop_words = set(stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "’ wishes ? cousin Westmoreland ? , fair cousin : mark ’ die , enow country loss ; live , fewer men , greater share honour . God ’ ! pray thee , wish one man . Jove , covetous gold , care doth feed upon cost ; yearns men garments wear ; outward things dwell desires : sin covet honour , offending soul alive . , faith , coz , wish man England : God ’ peace ! would lose great honour one man , methinks , would share best hope . , wish one ! Rather proclaim , Westmoreland , host , hath stomach fight , Let depart ; passport shall made crowns convoy put purse : would die man ’ company fears fellowship die us . day called feast Crispian : outlives day , comes safe home , stand tip-toe day named , rouse name Crispian .\n"
     ]
    }
   ],
   "source": [
    "def re_st(text):\n",
    "    words = word_tokenize(text)\n",
    "    n_word = [word for word in words if word.lower() not in stop_words]\n",
    "    return ' '.join(n_word)\n",
    "\n",
    "\n",
    "cl = re_st(\"\"\"What’s he that wishes so?\n",
    "My cousin Westmoreland? No, my fair cousin:\n",
    "If we are mark’d to die, we are enow\n",
    "To do our country loss; and if to live,\n",
    "The fewer men, the greater share of honour.\n",
    "God’s will! I pray thee, wish not one man more.\n",
    "By Jove, I am not covetous for gold,\n",
    "Nor care I who doth feed upon my cost;\n",
    "It yearns me not if men my garments wear;\n",
    "Such outward things dwell not in my desires:\n",
    "But if it be a sin to covet honour,\n",
    "I am the most offending soul alive.\n",
    "No, faith, my coz, wish not a man from England:\n",
    "God’s peace! I would not lose so great an honour\n",
    "As one man more, methinks, would share from me\n",
    "For the best hope I have. O, do not wish one more!\n",
    "Rather proclaim it, Westmoreland, through my host,\n",
    "That he which hath no stomach to this fight,\n",
    "Let him depart; his passport shall be made\n",
    "And crowns for convoy put into his purse:\n",
    "We would not die in that man’s company\n",
    "That fears his fellowship to die with us.\n",
    "This day is called the feast of Crispian:\n",
    "He that outlives this day, and comes safe home,\n",
    "Will stand a tip-toe when the day is named,\n",
    "And rouse him at the name of Crispian.\"\"\")\n",
    "print(cl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "’ wishes ? cousin Westmoreland ? , fair cousin : mark ’ die , enow\n",
      "country loss ; live , fewer men , greater share honour . God ’ ! pray\n",
      "thee , wish one man . Jove , covetous gold , care doth feed upon cost\n",
      "; yearns men garments wear ; outward things dwell desires : sin covet\n",
      "honour , offending soul alive . , faith , coz , wish man England : God\n",
      "’ peace ! would lose great honour one man , methinks , would share\n",
      "best hope . , wish one ! Rather proclaim , Westmoreland , host , hath\n",
      "stomach fight , Let depart ; passport shall made crowns convoy put\n",
      "purse : would die man ’ company fears fellowship die us . day called\n",
      "feast Crispian : outlives day , comes safe home , stand tip-toe day\n",
      "named , rouse name Crispian .\n"
     ]
    }
   ],
   "source": [
    "import textwrap\n",
    "\n",
    "def format_text(text, width=70):\n",
    "    return '\\n'.join(textwrap.wrap(text, width))\n",
    "\n",
    "formatted_cl = format_text(cl)\n",
    "print(formatted_cl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\shail\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\shail\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\shail\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "# Download necessary resources\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')\n",
    "\n",
    "def preprocess_sentence(sentence):\n",
    "    # Convert to lowercase\n",
    "    sentence = sentence.lower()\n",
    "\n",
    "    # Remove punctuation and special characters (except spaces)\n",
    "    sentence = re.sub(r'[^a-z\\s]', '', sentence)\n",
    "\n",
    "    # Tokenization\n",
    "    words = word_tokenize(sentence)\n",
    "\n",
    "    # Remove stopwords\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    words = [word for word in words if word not in stop_words]\n",
    "\n",
    "    # Lemmatization\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    words = [lemmatizer.lemmatize(word) for word in words]\n",
    "\n",
    "    return ' '.join(words)\n",
    "\n",
    "# Example Usage\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "not pass for hath no permission\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "# List of archaic English stopwords\n",
    "archaic_stopwords = {\n",
    "    \"thou\", \"thee\", \"thy\", \"thine\", \"ye\", \"hast\", \"dost\", \"doth\", \"shalt\", \"wilt\",\n",
    "    \"art\", \"tis\", \"twas\", \"hence\", \"whence\", \"wherefore\", \"oft\", \"ere\", \"nay\", \"aye\"\n",
    "}\n",
    "\n",
    "def remove_archaic_stopwords(text):\n",
    "    words = re.findall(r'\\b\\w+\\b', text)  # Extract words from text\n",
    "    filtered_text = ' '.join(word for word in words if word.lower() not in archaic_stopwords)\n",
    "    return filtered_text\n",
    "\n",
    "# Example usage\n",
    "text = \"Thou shalt not pass, for ye hath no permission.\"\n",
    "clean_text = remove_archaic_stopwords(text)\n",
    "print(clean_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "To own self be true and it must follow as the night the day canst not then be false to any man\n"
     ]
    }
   ],
   "source": [
    "clean_text = \"To thine own self be true, and it must follow, as the night the day, thou canst not then be false to any man.\"\n",
    "clean_text = remove_archaic_stopwords(clean_text)\n",
    "print(clean_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['react', 'precipitate']\n"
     ]
    }
   ],
   "source": [
    "def identify_chemistry_verbs(text):\n",
    "    chemistry_verbs = {\"react\", \"combine\", \"dissolve\", \"precipitate\", \"oxidize\", \"reduce\", \"neutralize\", \"synthesize\", \"analyze\", \"catalyze\"}\n",
    "    doc = nlp(text)\n",
    "    verbs = [token.text for token in doc if token.pos_ == \"VERB\" and token.lemma_ in chemistry_verbs]\n",
    "    return verbs\n",
    "\n",
    "# Example usage\n",
    "text = \"The solution will react and precipitate the solid compound.\"\n",
    "chemistry_verbs = identify_chemistry_verbs(text)\n",
    "print(chemistry_verbs)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
